# Credit-Risk-Model

**Session Overview:** The session focuses on machine learning concepts, particularly in model building and evaluation metrics.

- **Model Building:**
  - Discussion on using Python libraries for data handling and model building.
  - Emphasis on understanding the difference between various command-line tools such as *pip* and *conda*.
- **Data Exploration:**
  - Introduction to the dataset containing 42,000 rows and 43 columns.
  - Identification of key variables, including *Approval Flag* as the target variable.
- **Statistical Tests:**
  - Use of ANOVA and Chi-square tests for feature selection.
  - Explanation of how these tests help in identifying significant features related to the target variable.
- **Model Evaluation Metrics:**
  - *Accuracy:* Defined as the ratio of correctly predicted instances to the total instances.
  - *Recall:* Measures the ability of a model to identify all relevant instances, particularly important in imbalanced datasets.
  - *Precision:* Indicates the accuracy of the positive predictions made by the model.
  - *F1 Score:* The harmonic mean of precision and recall, useful for assessing model performance on imbalanced datasets.
  - *ROC-AUC:* A metric that evaluates the trade-off between true positive rates and false positive rates.
- **Feature Engineering:**
  - Importance of encoding categorical variables using techniques like One-Hot Encoding and Label Encoding.
  - Discussion on feature scaling and its impact on model performance.
- **Model Comparison:**
  - Comparison of different models such as Random Forest, XGBoost, and Decision Trees based on their accuracy and other metrics.
  - Identification of XGBoost as the best performing model in the session.

**Key Takeaways:**

- Understanding of various statistical tests and their relevance in feature selection.
- Importance of choosing the right evaluation metrics based on the nature of the dataset.
- Hands-on experience with model building and evaluation using Python libraries.
